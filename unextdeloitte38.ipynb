{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ezeAqna3-ZtY"
   },
   "source": [
    "# Project :6 Working with Structured Data: Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rWrIW-Bv-o23"
   },
   "source": [
    "In the realm of maritime operations, accurate detection and classification of underwater objects play a pivotal role in ensuring the safety and efficiency of various endeavours, ranging from underwater exploration to resource extraction. The Sonar dataset, comprising 208 observations, provides a comprehensive repository of sonar chirp returns, offering insights into the characteristics of submerged surfaces. With 60 input variables delineating the strength of returns at different angles, this dataset presents a formidable challenge: the binary classification of rocks and metal cylinders.By leveraging advanced predictive modelling techniques, our aim is to develop a robust solution capable of accurately discerning between these two distinct entities, thereby enhancing operational efficiency, and minimizing risks associated with underwater activities.\n",
    "\n",
    "        \n",
    "\n",
    "#### Data Set Description:\n",
    "\n",
    "The data set contains signals obtained from a variety of different aspect angles, spanning 90 degrees for the cylinder and 180 degrees for the rock. Each pattern is a set of 60 numbers in the range 0.0 to 1.0. Each number represents the energy within a particular frequency band, integrated over a certain period. The label associated with each record contains the letter \"R\" if the object is a rock and \"M\" if it is a mine (metal cylinder).  \n",
    "\n",
    "**Dataset : sonar.csv**\n",
    "\n",
    "Create a first step document that lists the output of your exploratory analysis, any issues, or problems you may see with data that need follow-up, and some basic descriptive analysis that you think highlights important outcomes/findings from the data. Based on your findings, the next level of analysis will be charted out. Build a predictive base model and use hyperparameter tuning to further optimize the accuracy of the predictions.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NKNwNQ3K_Zmq"
   },
   "source": [
    "**Initial Guidelines:**\n",
    "\n",
    "1.\tEnsure to follow to Use Idâ€™s provided by UNext for naming file as conventions.\n",
    "2.\tCreate GitHub account and submit the GitHub link."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Software Engineering aspect:  \n",
    "\n",
    "Utilize software engineering aspects while building Machine learning model using modular programming principles to organize your code into reusable functions or classes to enhance readability, maintainability, and collaboration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DA0XfSAd-hS9"
   },
   "source": [
    "### General Instructions \n",
    "\n",
    "- The cells in the Jupyter notebook can be executed any number of times for testing the solution\n",
    "- Refrain from modifying the boilerplate code as it may lead to unexpected behavior \n",
    "- The solution is to be written between the comments `# code starts here` and `# code ends here`\n",
    "- On completing all the questions, the assessment is to be submitted on moodle for evaluation\n",
    "- Before submitting the assessment, there should be `no error` while executing the notebook. If there are any error causing code, please comment it.\n",
    "- The kernel of the Jupyter notebook is to be set as `Python 3 (ipykernel)` if not set already\n",
    "- Include imports as necessary\n",
    "- For each of the task, `Note` section will provide you hints to solve the problem.\n",
    "- Do not use `PRINT` statement inside the `Except` Block. Please use `return` statement only within the except block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CtP8BJM7_f2V"
   },
   "source": [
    "#### **Utilize software engineering aspects while building the  model using modular programming principles to organize your code into reusable functions or classes to enhance readability, maintainability, and collaboration.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "lvqgkFGS1XTE"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-27 20:49:34.771928: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-27 20:49:34.840949: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-27 20:49:34.842167: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-27 20:49:35.900784: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# Required imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV, StratifiedKFold\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from joblib import dump,load\n",
    "import joblib\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wi-xguRr1wqP"
   },
   "source": [
    "### Task 1: Load the dataset and perform preliminary EDA with key observations and insights- (weightage - 20 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wt_fkG4Z1-Se"
   },
   "source": [
    "#### T1.1: Load the sonar dataset using try and except blocks.          (weightage - 2 marks) (AE)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE:\n",
    "- The `read_csv` method in Pandas allows you to read csv files and convert them into a DataFrame, which is a two-dimensional tabular data structure in Pandas.\n",
    "- Do not use `PRINT` statement inside the `Except` Block. Please use `return` statement only within the except block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "-hUjOO4D4wUQ"
   },
   "outputs": [],
   "source": [
    "def load_the_dataset():\n",
    "    try:\n",
    "    # code starts here\n",
    "      df_sonar = pd.read_csv(\"sonar1.csv\")\n",
    "    # code ends here\n",
    "      return df_sonar\n",
    "    except:\n",
    "        return \"File not found. Please check the file path.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2_jk7pNE2Ux2",
    "outputId": "00f6e5b0-3daf-44df-eab4-d74702d6fa71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Unnamed: 0  Attribute1  Attribute2  Attribute3  Attribute4  Attribute5  \\\n",
      "0             0      0.0200      0.0371      0.0428      0.0207      0.0954   \n",
      "1             1      0.0453      0.0523      0.0843      0.0689      0.1183   \n",
      "2             2      0.0262      0.0582      0.1099      0.1083      0.0974   \n",
      "3             3      0.0100      0.0171      0.0623      0.0205      0.0205   \n",
      "4             4      0.0762      0.0666      0.0481      0.0394      0.0590   \n",
      "..          ...         ...         ...         ...         ...         ...   \n",
      "203         203      0.0187      0.0346      0.0168      0.0177      0.0393   \n",
      "204         204      0.0323      0.0101      0.0298      0.0564      0.0760   \n",
      "205         205      0.0522      0.0437      0.0180      0.0292      0.0351   \n",
      "206         206      0.0303      0.0353      0.0490      0.0608      0.0167   \n",
      "207         207      0.0260      0.0363      0.0136      0.0272      0.0214   \n",
      "\n",
      "     Attribute6  Attribute7  Attribute8  Attribute9  ...  Attribute52  \\\n",
      "0        0.0986      0.1539      0.1601      0.3109  ...       0.0027   \n",
      "1        0.2583      0.2156      0.3481      0.3337  ...       0.0084   \n",
      "2        0.2280      0.2431      0.3771      0.5598  ...       0.0232   \n",
      "3        0.0368      0.1098      0.1276      0.0598  ...       0.0121   \n",
      "4        0.0649      0.1209      0.2467      0.3564  ...       0.0031   \n",
      "..          ...         ...         ...         ...  ...          ...   \n",
      "203      0.1630      0.2028      0.1694      0.2328  ...       0.0116   \n",
      "204      0.0958      0.0990      0.1018      0.1030  ...       0.0061   \n",
      "205      0.1171      0.1257      0.1178      0.1258  ...       0.0160   \n",
      "206      0.1354      0.1465      0.1123      0.1945  ...       0.0086   \n",
      "207      0.0338      0.0655      0.1400      0.1843  ...       0.0146   \n",
      "\n",
      "     Attribute53  Attribute54  Attribute55  Attribute56  Attribute57  \\\n",
      "0         0.0065       0.0159       0.0072       0.0167       0.0180   \n",
      "1         0.0089       0.0048       0.0094       0.0191       0.0140   \n",
      "2         0.0166       0.0095       0.0180       0.0244       0.0316   \n",
      "3         0.0036       0.0150       0.0085       0.0073       0.0050   \n",
      "4         0.0054       0.0105       0.0110       0.0015       0.0072   \n",
      "..           ...          ...          ...          ...          ...   \n",
      "203       0.0098       0.0199       0.0033       0.0101       0.0065   \n",
      "204       0.0093       0.0135       0.0063       0.0063       0.0034   \n",
      "205       0.0029       0.0051       0.0062       0.0089       0.0140   \n",
      "206       0.0046       0.0126       0.0036       0.0035       0.0034   \n",
      "207       0.0129       0.0047       0.0039       0.0061       0.0040   \n",
      "\n",
      "     Attribute58  Attribute59  Attribute60  class  \n",
      "0         0.0084       0.0090       0.0032      R  \n",
      "1         0.0049       0.0052       0.0044      R  \n",
      "2         0.0164       0.0095       0.0078      R  \n",
      "3         0.0044       0.0040       0.0117      R  \n",
      "4         0.0048       0.0107       0.0094      R  \n",
      "..           ...          ...          ...    ...  \n",
      "203       0.0115       0.0193       0.0157      M  \n",
      "204       0.0032       0.0062       0.0067      M  \n",
      "205       0.0138       0.0077       0.0031      M  \n",
      "206       0.0079       0.0036       0.0048      M  \n",
      "207       0.0036       0.0061       0.0115      M  \n",
      "\n",
      "[208 rows x 62 columns]\n"
     ]
    }
   ],
   "source": [
    "# store the result of the dataset\n",
    "df_sonar =load_the_dataset()\n",
    "print(df_sonar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HOhYH2Ns2epX"
   },
   "source": [
    "#### T1.2: What is the distribution of target variable? (Mention in percentage)(weightage - 2 marks)  (AE)             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE:\n",
    "\n",
    "* Design a method `target_class` to analyze the distribution of a target variable (\"class\") within a DataFrame (df). \n",
    "* Count the occurrences of each unique value in the 'class' column of the DataFrame df using the `value_counts` method\n",
    "* Normalizes the counts to obtain proportions instead of counts.\n",
    "* Scale the proportions to percentages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "PxSnZoUG2gsA"
   },
   "outputs": [],
   "source": [
    "def target_class(df):\n",
    "    #code starts here\n",
    "    class_counts = df['class'].value_counts()\n",
    "    class_proportions = class_counts/len(df)\n",
    "    target_dist = class_proportions*100\n",
    "    #code ends\n",
    "    return target_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sOve-YPr3SY3",
    "outputId": "d24fdbcb-b07d-49dc-b355-7c035cec0db8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M    53.365385\n",
      "R    46.634615\n",
      "Name: class, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# store the result\n",
    "target_distribution = target_class(df_sonar)\n",
    "print(target_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZM6CxQDW4j3b"
   },
   "source": [
    "#### T1.3: Remove the unnecessary column. (weightage - 2 marks)               (AE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note:\n",
    "* Unnamed: 0 is the unecessary column.\n",
    "* Use `drop` method of the dataframe to drop the unnecessary column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "LGgGQLE1f80f"
   },
   "outputs": [],
   "source": [
    "def unecessary_col(df):\n",
    "  #code starts here\n",
    "    df_updated = df.drop(\"Unnamed: 0\",axis=1)\n",
    "  #code ends here\n",
    "    return df_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i5U2e7Nk4wHt",
    "outputId": "8577ec29-9103-42d6-a7c9-4dab79887e3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Attribute1  Attribute2  Attribute3  Attribute4  Attribute5  Attribute6  \\\n",
      "0        0.0200      0.0371      0.0428      0.0207      0.0954      0.0986   \n",
      "1        0.0453      0.0523      0.0843      0.0689      0.1183      0.2583   \n",
      "2        0.0262      0.0582      0.1099      0.1083      0.0974      0.2280   \n",
      "3        0.0100      0.0171      0.0623      0.0205      0.0205      0.0368   \n",
      "4        0.0762      0.0666      0.0481      0.0394      0.0590      0.0649   \n",
      "..          ...         ...         ...         ...         ...         ...   \n",
      "203      0.0187      0.0346      0.0168      0.0177      0.0393      0.1630   \n",
      "204      0.0323      0.0101      0.0298      0.0564      0.0760      0.0958   \n",
      "205      0.0522      0.0437      0.0180      0.0292      0.0351      0.1171   \n",
      "206      0.0303      0.0353      0.0490      0.0608      0.0167      0.1354   \n",
      "207      0.0260      0.0363      0.0136      0.0272      0.0214      0.0338   \n",
      "\n",
      "     Attribute7  Attribute8  Attribute9  Attribute10  ...  Attribute52  \\\n",
      "0        0.1539      0.1601      0.3109       0.2111  ...       0.0027   \n",
      "1        0.2156      0.3481      0.3337       0.2872  ...       0.0084   \n",
      "2        0.2431      0.3771      0.5598       0.6194  ...       0.0232   \n",
      "3        0.1098      0.1276      0.0598       0.1264  ...       0.0121   \n",
      "4        0.1209      0.2467      0.3564       0.4459  ...       0.0031   \n",
      "..          ...         ...         ...          ...  ...          ...   \n",
      "203      0.2028      0.1694      0.2328       0.2684  ...       0.0116   \n",
      "204      0.0990      0.1018      0.1030       0.2154  ...       0.0061   \n",
      "205      0.1257      0.1178      0.1258       0.2529  ...       0.0160   \n",
      "206      0.1465      0.1123      0.1945       0.2354  ...       0.0086   \n",
      "207      0.0655      0.1400      0.1843       0.2354  ...       0.0146   \n",
      "\n",
      "     Attribute53  Attribute54  Attribute55  Attribute56  Attribute57  \\\n",
      "0         0.0065       0.0159       0.0072       0.0167       0.0180   \n",
      "1         0.0089       0.0048       0.0094       0.0191       0.0140   \n",
      "2         0.0166       0.0095       0.0180       0.0244       0.0316   \n",
      "3         0.0036       0.0150       0.0085       0.0073       0.0050   \n",
      "4         0.0054       0.0105       0.0110       0.0015       0.0072   \n",
      "..           ...          ...          ...          ...          ...   \n",
      "203       0.0098       0.0199       0.0033       0.0101       0.0065   \n",
      "204       0.0093       0.0135       0.0063       0.0063       0.0034   \n",
      "205       0.0029       0.0051       0.0062       0.0089       0.0140   \n",
      "206       0.0046       0.0126       0.0036       0.0035       0.0034   \n",
      "207       0.0129       0.0047       0.0039       0.0061       0.0040   \n",
      "\n",
      "     Attribute58  Attribute59  Attribute60  class  \n",
      "0         0.0084       0.0090       0.0032      R  \n",
      "1         0.0049       0.0052       0.0044      R  \n",
      "2         0.0164       0.0095       0.0078      R  \n",
      "3         0.0044       0.0040       0.0117      R  \n",
      "4         0.0048       0.0107       0.0094      R  \n",
      "..           ...          ...          ...    ...  \n",
      "203       0.0115       0.0193       0.0157      M  \n",
      "204       0.0032       0.0062       0.0067      M  \n",
      "205       0.0138       0.0077       0.0031      M  \n",
      "206       0.0079       0.0036       0.0048      M  \n",
      "207       0.0036       0.0061       0.0115      M  \n",
      "\n",
      "[208 rows x 61 columns]\n"
     ]
    }
   ],
   "source": [
    "#Store the result into a new dataframe\n",
    "df_sonar_updated = unecessary_col(df_sonar)\n",
    "print(df_sonar_updated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BlWK2YOM5cnK"
   },
   "source": [
    "#### T1.4: Check missing values in the data in terms of percentage and do missing value treatment.  (weightage - 2 marks)       (AE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE:\n",
    "- Find the percentage of missing values in the data by dividing the total number of missing values by the total number of rows and multiplying by 100, you will get the percentage of missing values for each column. \n",
    "- Use `isnull().sum()` to calculate the total number of missing values in each column and `shape[0]` to get the total number of rows in the DataFrame.\n",
    "- Do not use `PRINT` statement inside the `Except` Block. Please use `return` statement only within the except block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "PvO0lzXqfa4U"
   },
   "outputs": [],
   "source": [
    "def missing_value_check(df):\n",
    "    #Code starts here\n",
    "    missing_count = df.isnull().sum()\n",
    "    \n",
    "    total_rows = df.shape[0]\n",
    "    \n",
    "    missing_percentage = (missing_count/total_rows)*100\n",
    "    \n",
    "    return missing_percentage\n",
    "\n",
    "\n",
    "    # Code ends here   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_wWgPWS649LK",
    "outputId": "1da9ab48-251b-40b5-f35f-74651115e55a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Attribute1     0.0\n",
       "Attribute2     0.0\n",
       "Attribute3     0.0\n",
       "Attribute4     0.0\n",
       "Attribute5     0.0\n",
       "              ... \n",
       "Attribute57    0.0\n",
       "Attribute58    0.0\n",
       "Attribute59    0.0\n",
       "Attribute60    0.0\n",
       "class          0.0\n",
       "Length: 61, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_value_check(df_sonar_updated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE:\n",
    "* For treating the missing value first define the list of columns containing the names of the columns with missing values which will be treated. \n",
    "* Iterating over each column name in the columns list fill the missing values in the dataset for that column with the median value of that column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "u0ohbEqvhHwD"
   },
   "outputs": [],
   "source": [
    "# Missing value treatment\n",
    "def missing_value_treatment(df):\n",
    "# Code starts here\n",
    "    null_columns = df.isnull().any()\n",
    "    for col in null_columns.index[null_columns]:\n",
    "        df[col] = df[col].fillna(df[col].median())\n",
    "\n",
    "\n",
    "\n",
    "# Code ends here\n",
    "    return df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dN056jXQ6Nh2",
    "outputId": "937bdf8b-c866-47a7-caa0-3b54923675d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attribute1     0\n",
      "Attribute2     0\n",
      "Attribute3     0\n",
      "Attribute4     0\n",
      "Attribute5     0\n",
      "              ..\n",
      "Attribute57    0\n",
      "Attribute58    0\n",
      "Attribute59    0\n",
      "Attribute60    0\n",
      "class          0\n",
      "Length: 61, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Check if missing values are treated\n",
    "df_sonar_updated = missing_value_treatment(df_sonar_updated)\n",
    "print(df_sonar_updated.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0yOdDzyS7Aiq"
   },
   "source": [
    "#### T1.5: Visualize the correlation matrix using a heatmap for first 4 input variables. What is the Pearson correlation coefficient between the Attribute1 and Attribute 2? (Bivariate analysis) (weightage - 3 marks)               (AE and ME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE:\n",
    "* Define a method called `correlation_matrix` to calculate the Pearson correlation coefficient between two specific columns   ('Attribute 1' and 'Attribute 2') in a DataFrame (df).\n",
    "* Use the `iloc` method to select only the columns corresponding to 'Attribute 1' and 'Attribute 2' from the DataFrame df.\n",
    "* Calculate the Pearson correlation coefficient using the corr() method on the selected columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "c1jWoKmt55Hi"
   },
   "outputs": [],
   "source": [
    "# Pearson correlation coefficient for Attribute 1 and Attribute 2\n",
    "def correlation_matrix(df):\n",
    "    # Code starts here\n",
    "    df_subset = df.iloc[:,:4]\n",
    "    corr_matrix = df_subset.corr(method= 'pearson')\n",
    "    correlation = corr_matrix['Attribute1']['Attribute2']\n",
    "#     sns.heatmap(corr_matrix, annot = True)\n",
    "#     plt.show()\n",
    "    # Code ends here\n",
    "    return correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J9taquCL78Wm",
    "outputId": "467e068e-bc43-47dc-a73a-1ad8951a24ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7358956043135684\n"
     ]
    }
   ],
   "source": [
    "Correlation_Attribute_1_2 = correlation_matrix(df_sonar_updated)\n",
    "print(Correlation_Attribute_1_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE:\n",
    "* Generate a heatmap visualization of the correlation matrix for the specified subset of columns in the DataFrame \n",
    "* Select the first four columns (indexed 0, 1, 2, and 3) of the DataFrame using integer-based indexing. \n",
    "* Using seaborn `heatmap` method, generate a heatmap plot of the correlation matrix.\n",
    "* Using `annot` parameter, display correlation coefficients inside each cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "id": "rpkyDMBi8GWQ",
    "outputId": "4481533f-801f-4c4b-cf36-29e4aaebcc2b"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualize using Heatmap\n",
    "df_subset = df_sonar_updated.iloc[:,:4]\n",
    "corr_matrix = df_subset.corr(method= 'pearson')\n",
    "sns.heatmap(corr_matrix, annot = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nEg2xZQX8cF4"
   },
   "source": [
    "#### T1.6. Perform PCA (Principal Component Analysis) on the input variables. Display the cumulative variance array along with the number of principal components required to capture 90% of information. How many principal components are required to capture 90% of the information?  (AE) 2 Marks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note\n",
    "\n",
    "* Define a method called `pca_inputs` to perform Principal Component Analysis (PCA) on the input DataFrame (df) for the first 60 columns.\n",
    "* Create a copy of the first 60 columns of the DataFrame df.* and assign it to a new DataFrame `df2`.\n",
    "* Initialize a StandardScaler object (sc) to standardize the data.\n",
    "* Standardize the data in `df2` using sc.fit_transform(df2), and store the standardized data in a new DataFrame dfsc.\n",
    "* Convert dfsc back to a DataFrame with column names from df2 using pd.DataFrame(dfsc, columns=df2.columns)\n",
    "* Initialize a PCA object (finalpca) for performing PCA.\n",
    "* Perform PCA on the standardized data dfsc using `finalpca.fit_transform(dfsc)` and store the transformed data in finaldf.\n",
    "* Obtain the explained variance ratio of each principal component using finalpca.explained_variance_ratio_\n",
    "* Calculate the number of principal components needed to explain at least 90% of the variance by iterating through the cumulative sum of explained variances (np.cumsum(variation))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "2XKv6Xg18xrG"
   },
   "outputs": [],
   "source": [
    "def pca_inputs(df):\n",
    "    \n",
    "    df2 = df.iloc[:,:60].copy()\n",
    "    sc = StandardScaler()\n",
    "    dfsc = sc.fit_transform(df2)\n",
    "    dfsc = pd.DataFrame(dfsc,columns=df2.columns)\n",
    "    \n",
    "    #Peform PCA\n",
    "    \n",
    "    finalpca = PCA()\n",
    "    finaldf = finalpca.fit_transform(dfsc)\n",
    "    \n",
    "    variation = finalpca.explained_variance_ratio_\n",
    "    \n",
    "    cumulative_variance = np.cumsum(variation)\n",
    "    count = np.argmax(cumulative_variance >=0.9)+1\n",
    "    \n",
    "    return cumulative_variance,count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eSvXGdgF8xts",
    "outputId": "7bc0a5dc-049f-4a6e-d068-c6d484fe486c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cumulative variance :[0.20372013 0.39240256 0.47791603 0.53442693 0.58446497 0.62513389\n",
      " 0.6576164  0.68827564 0.71340088 0.73707394 0.75846917 0.77747927\n",
      " 0.79495787 0.81021968 0.82454013 0.83809472 0.85041426 0.86212083\n",
      " 0.87247607 0.88235948 0.89193517 0.90088052 0.90940274 0.91713441\n",
      " 0.92442858 0.93156896 0.93782163 0.94335663 0.94860861 0.95381911\n",
      " 0.95854518 0.96299091 0.9666294  0.97008747 0.9734147  0.97642876\n",
      " 0.97930819 0.98181733 0.98407149 0.98607485 0.98785671 0.98944904\n",
      " 0.99080305 0.99204566 0.99310904 0.99408868 0.99503067 0.9957696\n",
      " 0.99637763 0.9969047  0.99740263 0.99787272 0.99827773 0.99866079\n",
      " 0.9989825  0.99925705 0.9995042  0.99969824 0.99988887 1.        ]\n",
      "Number of principal components that capture 90% of information :22\n"
     ]
    }
   ],
   "source": [
    "# Print the cumulative variance and specify the number of principal components that capture 90% of information\n",
    "cumulative_variance,count = pca_inputs(df_sonar_updated)\n",
    "print(f'Cumulative variance :{cumulative_variance}')\n",
    "print(f'Number of principal components that capture 90% of information :{count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zcLA99Hs_gHL"
   },
   "source": [
    "#### T1.7: Data Transformation:  Apply normalization technique (standard scalar). (weightage - 3 marks)        (AE)       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note\n",
    "\n",
    "* Define a method called `normalize` to normalize the first 60 columns of a DataFrame (df).\n",
    "* Use the `iloc` method to select the first 60 columns of the DataFrame df, and apply the StandardScaler to standardize these columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "bTD4LjVJ8xwN"
   },
   "outputs": [],
   "source": [
    "def normalize(df):\n",
    "    \n",
    "    df_n = df.iloc[:,:60].copy()\n",
    "    sc = StandardScaler()\n",
    "    df_norm = pd.DataFrame(sc.fit_transform(df_n),columns = df_n.columns)\n",
    "    df_norm = pd.concat([df_norm,df.iloc[:,60:]],axis=1)\n",
    "    \n",
    "    return df_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RopgyCSU8xyv",
    "outputId": "bd6b952a-1b6a-42db-8dd1-d70160f6440c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Attribute1  Attribute2  Attribute3  Attribute4  Attribute5  Attribute6  \\\n",
      "0     -0.399551   -0.040648   -0.026926   -0.715105    0.364456   -0.101253   \n",
      "1      0.703538    0.421630    1.055618    0.323330    0.777676    2.607217   \n",
      "2     -0.129229    0.601067    1.723404    1.172176    0.400545    2.093337   \n",
      "3     -0.835555   -0.648910    0.481740   -0.719414   -0.987079   -1.149364   \n",
      "4      2.050790    0.856537    0.111327   -0.312227   -0.292365   -0.672796   \n",
      "..          ...         ...         ...         ...         ...         ...   \n",
      "203   -0.456232   -0.116681   -0.705146   -0.779738   -0.647842    0.990954   \n",
      "204    0.136733   -0.861801   -0.366036    0.054026    0.014392   -0.148740   \n",
      "205    1.004381    0.160078   -0.673843   -0.531979   -0.723629    0.212502   \n",
      "206    0.049533   -0.095392    0.134804    0.148821   -1.055648    0.522865   \n",
      "207   -0.137949   -0.064979   -0.788619   -0.575067   -0.970839   -1.200244   \n",
      "\n",
      "     Attribute7  Attribute8  Attribute9  Attribute10  ...  Attribute52  \\\n",
      "0      0.682505    0.297843    1.125272     0.021186  ...    -1.115432   \n",
      "1      1.795719    2.510982    1.318325     0.588706  ...    -0.522349   \n",
      "2      2.291885    2.852370    3.232767     3.066105  ...     1.017585   \n",
      "3     -0.113164   -0.084747   -1.000852    -0.610469  ...    -0.137365   \n",
      "4      0.087107    1.317299    1.510531     1.772220  ...    -1.073812   \n",
      "..          ...         ...         ...          ...  ...          ...   \n",
      "203    1.564777    0.407323    0.463980     0.448504  ...    -0.189390   \n",
      "204   -0.308022   -0.388465   -0.635067     0.053253  ...    -0.761663   \n",
      "205    0.173710   -0.200113   -0.442014     0.332912  ...     0.268428   \n",
      "206    0.548991   -0.264859    0.139685     0.202404  ...    -0.501539   \n",
      "207   -0.912441    0.061226    0.053319     0.202404  ...     0.122759   \n",
      "\n",
      "     Attribute53  Attribute54  Attribute55  Attribute56  Attribute57  \\\n",
      "0      -0.597604     0.680897    -0.295646     1.481635     1.763784   \n",
      "1      -0.256857    -0.843151     0.015503     1.901046     1.070732   \n",
      "2       0.836373    -0.197833     1.231812     2.827246     4.120162   \n",
      "3      -1.009341     0.557326    -0.111785    -0.161060    -0.488635   \n",
      "4      -0.753780    -0.060532     0.241793    -1.174638    -0.107456   \n",
      "..           ...          ...          ...          ...          ...   \n",
      "203    -0.129077     1.230104    -0.847228     0.328253    -0.228741   \n",
      "204    -0.200066     0.351373    -0.422934    -0.335815    -0.765856   \n",
      "205    -1.108725    -0.801960    -0.437077     0.118548     1.070732   \n",
      "206    -0.867363     0.227802    -0.804798    -0.825128    -0.765856   \n",
      "207     0.311055    -0.856881    -0.762369    -0.370766    -0.661898   \n",
      "\n",
      "     Attribute58  Attribute59  Attribute60  class  \n",
      "0       0.069870     0.171678    -0.658947      R  \n",
      "1      -0.472406    -0.444554    -0.419852      R  \n",
      "2       1.309360     0.252761     0.257582      R  \n",
      "3      -0.549875    -0.639154     1.034640      R  \n",
      "4      -0.487900     0.447361     0.576375      R  \n",
      "..           ...          ...          ...    ...  \n",
      "203     0.550172     1.841992     1.831621      M  \n",
      "204    -0.735798    -0.282388     0.038412      M  \n",
      "205     0.906526    -0.039138    -0.678871      M  \n",
      "206    -0.007598    -0.704020    -0.340154      M  \n",
      "207    -0.673823    -0.298604     0.994790      M  \n",
      "\n",
      "[208 rows x 61 columns]\n"
     ]
    }
   ],
   "source": [
    "# Save the standardized data\n",
    "df_normalized = normalize(df_sonar_updated)\n",
    "print(df_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mGH-2yFqAMoH"
   },
   "source": [
    "#### T1.8: Handling categorical features: Apply label encoding technique to convert categorical variable into numerical. (weightage - 2 marks) (AE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE:\n",
    "\n",
    "* Define a method called `label_encode` to perform label encoding on a categorical column ('class') in a DataFrame (df).\n",
    "* Initialize a LabelEncoder object (encoder) for encoding categorical labels.\n",
    "* Use encoder.fit_transform(df[['class']]) to fit and transform the 'class' column into encoded labels. Wrap the result in a DataFrame using pd.DataFrame(...) and assign it to encoded_y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "7GGwrKUI8x2F"
   },
   "outputs": [],
   "source": [
    "def label_encode(df):\n",
    "    # Code starts here\n",
    "    categorical_column = 'class'\n",
    "    encoder = LabelEncoder()\n",
    "    encoded_y = pd.DataFrame(encoder.fit_transform(df[categorical_column]), columns= [categorical_column])\n",
    "    df_encoded = pd.concat([df.drop(categorical_column,axis=1),encoded_y],axis = 1)\n",
    "    # Code ends here\n",
    "    return encoded_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "15bzftDICe1q",
    "outputId": "7444ed20-0a70-441c-9636-c9638c486ee8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     class\n",
      "0        1\n",
      "1        1\n",
      "2        1\n",
      "3        1\n",
      "4        1\n",
      "..     ...\n",
      "203      0\n",
      "204      0\n",
      "205      0\n",
      "206      0\n",
      "207      0\n",
      "\n",
      "[208 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# Apply label encoding to class variable\n",
    "encoded_class = label_encode(df_sonar_updated)\n",
    "print(encoded_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kqk4Qh1NDN_P"
   },
   "source": [
    "#### T1.9: Save the cleaned dataset (.xlsx file) by setting the index=False in your GitHub repository for model building process. (This task is for maintaining the version control of datasets)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Refer to the Github document from Lumen to create the repository and steps to commit \n",
    "#### Add your Github repository link below "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/Sarthak-Tuteja/usecase6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE:\n",
    "* Concatenate two DataFrames `df_normalized` and `encoded_class` horizontally along the `columns` using the `concat` method\n",
    "* Using `to_excel` method and setting `index` parameter to `False` save the final dataset in __EXCEL [.xlsx]__ format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "BszPzlACDPwe"
   },
   "outputs": [],
   "source": [
    "df_normalized.drop('class',axis=1,inplace= True)\n",
    "df_final = pd.concat([df_normalized,encoded_class],axis=1)\n",
    "df_final.to_excel('df_final.xlsx',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "8NPSwxMaGYu1"
   },
   "outputs": [],
   "source": [
    "# save it in github repository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YNVfVICBDknW"
   },
   "source": [
    "### Task 2: Build a Neural Network Predictive Model with Grid Search (weightage - 30 marks)               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-neHX2NrEhLt"
   },
   "source": [
    "#### T2.1: Load the cleaned dataset and divide it into predictor and target values (X & y) (weightage â€“ 5 marks) (AE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE:\n",
    "\n",
    "* Define a method called `load_the_cleaned_dataset` to load a cleaned dataset from an Excel file named 'df_final.xlsx'.\n",
    "* Use the `pd.read_excel` function to read the Excel file and store the data in a DataFrame called cleaned_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "2vcS5frK6HBm"
   },
   "outputs": [],
   "source": [
    "# load the cleaned data\n",
    "def load_the_cleaned_dataset():\n",
    "        \n",
    "\n",
    "        # Code starts here\n",
    "        cleaned_df = pd.read_excel('df_final.xlsx')\n",
    "\n",
    "        # Code ends here\n",
    "        return cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df=load_the_cleaned_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qCxduowDG4e6"
   },
   "source": [
    "- Separate independent features and target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE\n",
    "\n",
    "* Define a method called `separate_data_and_target` to separate the independent features and the target variable from a DataFrame (df).\n",
    "* Use the `drop` method on the DataFrame df to create a new DataFrame `X` containing only the independent features. Drop the `class` column along the columns axis (axis=1).\n",
    "* Create a Series `y` containing the target variable by selecting only the `class` column from the original DataFrame df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "EE27qRiE7En_"
   },
   "outputs": [],
   "source": [
    "# Separate independent features and target variable\n",
    "def separate_data_and_target(df):\n",
    "    # Code starts here\n",
    "    X = df.drop('class',axis=1)\n",
    "    y = df['class']\n",
    "    # Code ends here\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zipPZZTzG_Xh",
    "outputId": "6766efcc-9527-4b32-b3a2-29d42ba80ca8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208, 60)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dependent : X, independent : y\n",
    "X, y = separate_data_and_target(cleaned_df)\n",
    "X.shape\n",
    "#y.shape\n",
    "#print(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BA_sF11OHI7R",
    "outputId": "f3a0ab90-0bc4-4158-bea9-2572f3bb98a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RmBLM3NWF3KM"
   },
   "source": [
    "#### T2.2: Split the dataset into train and test in the ratio of 80:20. (weightage â€“ 5 marks) (AE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE\n",
    "* Define a method called `split_into_train_and_test_normalize_features` to split the features (X) and target variable (y) into training and testing sets, and normalize the features.\n",
    "* Use the `train_test_split` function to split the features (X) and target variable (y) into training and testing sets. Specify the test size as 20% (test_size = .2) and set a random state for reproducibility (random_state=0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "4JsY8CR9BbsT"
   },
   "outputs": [],
   "source": [
    "def split_into_train_and_test_normalize_features(X,y):\n",
    "    # Code starts here\n",
    "# Splitting dataset to train and test sets 80% train and 20% test\n",
    "    \n",
    "    X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=0)\n",
    "    \n",
    "    # Code ends here\n",
    "    return X_train, X_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "ieJZPscjHFj9"
   },
   "outputs": [],
   "source": [
    "# split into training and testing\n",
    "X_train, X_test,y_train,y_test=split_into_train_and_test_normalize_features(X,y)\n",
    "#X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "03vqMsbKGfHp"
   },
   "source": [
    "#### Build NN model on training data.Perform hyperparameter tuning using Grid Search. What are the epochs, batch size, and optimizers were selected using grid search?\n",
    "\n",
    "**Model_versioning**\n",
    "\n",
    "Save the model as â€˜NN_modelâ€™ to a version control system GitHub using git commands for collaboration, tracking changes, and ensuring transparency in model development. --- (weightage 20 marks ) (ME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE\n",
    "\n",
    "* Define a method called `create_baseline` to create a baseline neural network model.\n",
    "* Inside the method:\n",
    "    * Create a Sequential model using Sequential() from Keras.\n",
    "    * Add a Dense layer with 60 units (assuming 60 input features), specify input_dim=60, use 'normal' kernel initializer, and set activation='relu'.\n",
    "    * Add another Dense layer with 1 unit for binary classification, use 'normal' kernel initializer, and set activation='sigmoid'.\n",
    "    * Compile the model using model.compile() with 'binary_crossentropy' as the loss function, 'adam' optimizer, and include 'accuracy' as a metric.\n",
    "* Create Pipeline and Grid Search:\n",
    "    * Create a pipeline using Pipeline from sklearn.pipeline.\n",
    "    * Include the KerasClassifier within the pipeline, specifying the build function as create_baseline and set verbose=0.\n",
    "    * Define the grid search parameters in a dictionary param_grid, such as different batch sizes and epochs.\n",
    "* Perform Grid Search:\n",
    "    * Initialize a StratifiedKFold with the desired number of splits (e.g., StratifiedKFold(n_splits=10, shuffle=True)).\n",
    "    * Use GridSearchCV with the pipeline, parameter grid (param_grid), and cross-validation strategy (cv=kfold) to perform grid search.\n",
    "    * Fit the grid search object to your training data (X_train, y_train) to find the best model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_baseline():\n",
    "    \n",
    "    # Code starts here\n",
    "    \n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Dense(60,activation='relu',input_dim=60,kernel_initializer='normal'))\n",
    "    model.compile(loss='binary_crossentropy',optimizer = 'adam',metrics =['accuracy'])\n",
    "    \n",
    "    # Code ends here\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9296/2764586727.py:2: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  pipe = Pipeline([('clf',KerasClassifier(build_fn=create_baseline,verbose=0))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f3a70c84160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f3aa2bfc9d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=True),\n",
       "             estimator=Pipeline(steps=[(&#x27;clf&#x27;,\n",
       "                                        &lt;keras.wrappers.scikit_learn.KerasClassifier object at 0x7f3aa2df6790&gt;)]),\n",
       "             param_grid={&#x27;clf__batch_size&#x27;: [2, 5, 10, 15],\n",
       "                         &#x27;clf__epochs&#x27;: [130, 140, 150, 160, 170]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=True),\n",
       "             estimator=Pipeline(steps=[(&#x27;clf&#x27;,\n",
       "                                        &lt;keras.wrappers.scikit_learn.KerasClassifier object at 0x7f3aa2df6790&gt;)]),\n",
       "             param_grid={&#x27;clf__batch_size&#x27;: [2, 5, 10, 15],\n",
       "                         &#x27;clf__epochs&#x27;: [130, 140, 150, 160, 170]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;clf&#x27;,\n",
       "                 &lt;keras.wrappers.scikit_learn.KerasClassifier object at 0x7f3aa2df6790&gt;)])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KerasClassifier</label><div class=\"sk-toggleable__content\"><pre>&lt;keras.wrappers.scikit_learn.KerasClassifier object at 0x7f3aa2df6790&gt;</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=True),\n",
       "             estimator=Pipeline(steps=[('clf',\n",
       "                                        <keras.wrappers.scikit_learn.KerasClassifier object at 0x7f3aa2df6790>)]),\n",
       "             param_grid={'clf__batch_size': [2, 5, 10, 15],\n",
       "                         'clf__epochs': [130, 140, 150, 160, 170]})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create pipeline\n",
    "pipe = Pipeline([('clf',KerasClassifier(build_fn=create_baseline,verbose=0))])\n",
    "\n",
    "# define the grid search parameters\n",
    "param_grid = {\n",
    "    'clf__epochs': [130,140,150,160,170],\n",
    "    'clf__batch_size' : [2,5,10,15]\n",
    "}\n",
    "\n",
    "# perform grid search\n",
    "kfold = StratifiedKFold(n_splits=10,shuffle=True)\n",
    "grid_search = GridSearchCV(estimator=pipe,param_grid=param_grid,cv = kfold)\n",
    "grid_search.fit(X_train,y_train)\n",
    "\n",
    "# summarize results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('clf',\n",
      "                 <keras.wrappers.scikit_learn.KerasClassifier object at 0x7f3a3536d550>)])\n"
     ]
    }
   ],
   "source": [
    "# summarize results\n",
    "best_model = grid_search.best_estimator_\n",
    "print(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf__batch_size': 2, 'clf__epochs': 170}\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21066176593303682\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5LljG34t2erm"
   },
   "source": [
    "The results indicate the performance of the baseline model and its variations with different hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE\n",
    "* Utilizes Keras and scikit-learn to create and train a neural network model with the specified parameters.\n",
    "* Train the model on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fOmzw30_2g2Q",
    "outputId": "715d6800-a42e-4694-eff0-65d4a4316e03"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pipeline.joblib']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(pipe,'pipeline.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "34/34 [==============================] - 1s 1ms/step - loss: 3.8047 - accuracy: 0.0422 \n",
      "Epoch 2/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3.0943 - accuracy: 0.0482\n",
      "Epoch 3/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2.7253 - accuracy: 0.0181\n",
      "Epoch 4/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2.5195 - accuracy: 0.0181\n",
      "Epoch 5/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2.3604 - accuracy: 0.0301\n",
      "Epoch 6/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2.2257 - accuracy: 0.0361\n",
      "Epoch 7/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2.1171 - accuracy: 0.0482\n",
      "Epoch 8/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 2.0350 - accuracy: 0.0602\n",
      "Epoch 9/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 1.9778 - accuracy: 0.0542\n",
      "Epoch 10/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 1.9300 - accuracy: 0.0422\n",
      "Epoch 11/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 1.8618 - accuracy: 0.0361\n",
      "Epoch 12/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 1.8237 - accuracy: 0.0422\n",
      "Epoch 13/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 1.7928 - accuracy: 0.0361\n",
      "Epoch 14/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 1.7669 - accuracy: 0.0422\n",
      "Epoch 15/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 1.7462 - accuracy: 0.0301\n",
      "Epoch 16/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 1.7187 - accuracy: 0.0301\n",
      "Epoch 17/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 1.6900 - accuracy: 0.0181\n",
      "Epoch 18/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 1.6640 - accuracy: 0.0241\n",
      "Epoch 19/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 1.6440 - accuracy: 0.0181\n",
      "Epoch 20/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 1.6334 - accuracy: 0.0241\n",
      "Epoch 21/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 1.6199 - accuracy: 0.0301\n",
      "Epoch 22/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 1.6010 - accuracy: 0.0361\n",
      "Epoch 23/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 1.5883 - accuracy: 0.0241\n",
      "Epoch 24/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 1.5752 - accuracy: 0.0361\n",
      "Epoch 25/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 1.5534 - accuracy: 0.0482\n",
      "Epoch 26/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 1.5434 - accuracy: 0.0602\n",
      "Epoch 27/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 1.5295 - accuracy: 0.0663\n",
      "Epoch 28/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 1.5113 - accuracy: 0.0542\n",
      "Epoch 29/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 1.4981 - accuracy: 0.0602\n",
      "Epoch 30/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 1.4856 - accuracy: 0.0602\n",
      "Epoch 31/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 1.4662 - accuracy: 0.0542\n",
      "Epoch 32/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 1.4637 - accuracy: 0.0542\n",
      "Epoch 33/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 1.4524 - accuracy: 0.0482\n",
      "Epoch 34/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 1.4384 - accuracy: 0.0482\n",
      "Epoch 35/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 1.4279 - accuracy: 0.0482\n",
      "Epoch 36/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 1.4158 - accuracy: 0.0542\n",
      "Epoch 37/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 1.4018 - accuracy: 0.0602\n",
      "Epoch 38/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 1.3856 - accuracy: 0.0602\n",
      "Epoch 39/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 1.3773 - accuracy: 0.0602\n",
      "Epoch 40/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 1.3687 - accuracy: 0.0602\n",
      "Epoch 41/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 1.3639 - accuracy: 0.0602\n",
      "Epoch 42/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 1.3589 - accuracy: 0.0663\n",
      "Epoch 43/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 1.3546 - accuracy: 0.0723\n",
      "Epoch 44/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 1.3491 - accuracy: 0.0723\n",
      "Epoch 45/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 1.3429 - accuracy: 0.0723\n",
      "Epoch 46/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 1.3389 - accuracy: 0.0723\n",
      "Epoch 47/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 1.3278 - accuracy: 0.0843\n",
      "Epoch 48/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 1.3242 - accuracy: 0.0843\n",
      "Epoch 49/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 1.3196 - accuracy: 0.0783\n",
      "Epoch 50/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 1.3088 - accuracy: 0.0783\n",
      "Epoch 51/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 1.2992 - accuracy: 0.0843\n",
      "Epoch 52/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 1.2961 - accuracy: 0.0843\n",
      "Epoch 53/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 1.2865 - accuracy: 0.0843\n",
      "Epoch 54/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 1.2789 - accuracy: 0.0783\n",
      "Epoch 55/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 1.2751 - accuracy: 0.0783\n",
      "Epoch 56/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 1.2729 - accuracy: 0.0843\n",
      "Epoch 57/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 1.2692 - accuracy: 0.0843\n",
      "Epoch 58/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 1.2558 - accuracy: 0.0843\n",
      "Epoch 59/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 1.2443 - accuracy: 0.0843\n",
      "Epoch 60/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 1.2370 - accuracy: 0.1024\n",
      "Epoch 61/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 1.2309 - accuracy: 0.0964\n",
      "Epoch 62/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 1.2239 - accuracy: 0.1024\n",
      "Epoch 63/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 1.2144 - accuracy: 0.1566\n",
      "Epoch 64/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 1.2034 - accuracy: 0.1566\n",
      "Epoch 65/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 1.1909 - accuracy: 0.1506\n",
      "Epoch 66/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 1.1729 - accuracy: 0.1386\n",
      "Epoch 67/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 1.1606 - accuracy: 0.1265\n",
      "Epoch 68/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 1.1557 - accuracy: 0.1386\n",
      "Epoch 69/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 1.1487 - accuracy: 0.1205\n",
      "Epoch 70/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 1.1408 - accuracy: 0.1205\n",
      "Epoch 71/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 1.1335 - accuracy: 0.1205\n",
      "Epoch 72/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 1.1279 - accuracy: 0.1205\n",
      "Epoch 73/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 1.1197 - accuracy: 0.1265\n",
      "Epoch 74/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 1.1163 - accuracy: 0.1205\n",
      "Epoch 75/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 1.1140 - accuracy: 0.1205\n",
      "Epoch 76/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 1.1120 - accuracy: 0.1205\n",
      "Epoch 77/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 1.1090 - accuracy: 0.1205\n",
      "Epoch 78/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 1.1050 - accuracy: 0.1205\n",
      "Epoch 79/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 1.1044 - accuracy: 0.1205\n",
      "Epoch 80/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 1.1003 - accuracy: 0.1205\n",
      "Epoch 81/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 1.0980 - accuracy: 0.1205\n",
      "Epoch 82/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 1.0932 - accuracy: 0.1205\n",
      "Epoch 83/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 1ms/step - loss: 1.0895 - accuracy: 0.1205\n",
      "Epoch 84/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 1.0876 - accuracy: 0.1265\n",
      "Epoch 85/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 1.0825 - accuracy: 0.1205\n",
      "Epoch 86/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 1.0770 - accuracy: 0.1265\n",
      "Epoch 87/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 1.0727 - accuracy: 0.1145\n",
      "Epoch 88/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 1.0660 - accuracy: 0.1145\n",
      "Epoch 89/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 1.0619 - accuracy: 0.1084\n",
      "Epoch 90/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 1.0589 - accuracy: 0.1145\n",
      "Epoch 91/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 1.0574 - accuracy: 0.1325\n",
      "Epoch 92/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 1.0559 - accuracy: 0.1265\n",
      "Epoch 93/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 1.0560 - accuracy: 0.1265\n",
      "Epoch 94/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 1.0504 - accuracy: 0.1205\n",
      "Epoch 95/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 1.0440 - accuracy: 0.1265\n",
      "Epoch 96/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 1.0423 - accuracy: 0.1325\n",
      "Epoch 97/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 1.0414 - accuracy: 0.1265\n",
      "Epoch 98/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 1.0417 - accuracy: 0.1325\n",
      "Epoch 99/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 1.0378 - accuracy: 0.1265\n",
      "Epoch 100/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 1.0361 - accuracy: 0.1325\n",
      "Epoch 101/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 1.0297 - accuracy: 0.1325\n",
      "Epoch 102/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 1.0258 - accuracy: 0.1325\n",
      "Epoch 103/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 1.0209 - accuracy: 0.1265\n",
      "Epoch 104/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 1.0187 - accuracy: 0.1325\n",
      "Epoch 105/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 1.0152 - accuracy: 0.1325\n",
      "Epoch 106/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 1.0114 - accuracy: 0.1265\n",
      "Epoch 107/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 1.0086 - accuracy: 0.1325\n",
      "Epoch 108/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 1.0061 - accuracy: 0.1386\n",
      "Epoch 109/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 1.0039 - accuracy: 0.1325\n",
      "Epoch 110/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 1.0006 - accuracy: 0.1506\n",
      "Epoch 111/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.9988 - accuracy: 0.1506\n",
      "Epoch 112/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.9970 - accuracy: 0.1265\n",
      "Epoch 113/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.9948 - accuracy: 0.1627\n",
      "Epoch 114/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.9937 - accuracy: 0.1627\n",
      "Epoch 115/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.9921 - accuracy: 0.1566\n",
      "Epoch 116/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.9885 - accuracy: 0.1627\n",
      "Epoch 117/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.9866 - accuracy: 0.1506\n",
      "Epoch 118/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.9848 - accuracy: 0.1325\n",
      "Epoch 119/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.9758 - accuracy: 0.1386\n",
      "Epoch 120/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.9728 - accuracy: 0.1386\n",
      "Epoch 121/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.9728 - accuracy: 0.1325\n",
      "Epoch 122/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.9695 - accuracy: 0.1446\n",
      "Epoch 123/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.9660 - accuracy: 0.1386\n",
      "Epoch 124/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.9641 - accuracy: 0.1325\n",
      "Epoch 125/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.9616 - accuracy: 0.1325\n",
      "Epoch 126/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.9565 - accuracy: 0.1325\n",
      "Epoch 127/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.9565 - accuracy: 0.1386\n",
      "Epoch 128/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.9521 - accuracy: 0.1386\n",
      "Epoch 129/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.9437 - accuracy: 0.1566\n",
      "Epoch 130/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.9397 - accuracy: 0.1807\n",
      "Epoch 131/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.9369 - accuracy: 0.1747\n",
      "Epoch 132/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.9382 - accuracy: 0.1747\n",
      "Epoch 133/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.9339 - accuracy: 0.1687\n",
      "Epoch 134/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.9297 - accuracy: 0.1627\n",
      "Epoch 135/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.9311 - accuracy: 0.1627\n",
      "Epoch 136/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.9265 - accuracy: 0.1627\n",
      "Epoch 137/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.9245 - accuracy: 0.1747\n",
      "Epoch 138/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.9234 - accuracy: 0.1687\n",
      "Epoch 139/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.9223 - accuracy: 0.1627\n",
      "Epoch 140/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.9197 - accuracy: 0.1566\n",
      "Epoch 141/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.9254 - accuracy: 0.1446\n",
      "Epoch 142/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.9216 - accuracy: 0.1506\n",
      "Epoch 143/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.9190 - accuracy: 0.1627\n",
      "Epoch 144/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.9152 - accuracy: 0.1687\n",
      "Epoch 145/150\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.9118 - accuracy: 0.1687\n",
      "Epoch 146/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.9100 - accuracy: 0.1687\n",
      "Epoch 147/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.9091 - accuracy: 0.1687\n",
      "Epoch 148/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.9090 - accuracy: 0.1687\n",
      "Epoch 149/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.9077 - accuracy: 0.1687\n",
      "Epoch 150/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.9036 - accuracy: 0.1747\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(60,activation='relu',input_dim=60,kernel_initializer='normal'))\n",
    "model.compile(loss='binary_crossentropy',optimizer = 'adam',metrics =['accuracy'])\n",
    "model.fit(X_train,y_train,epochs=150,batch_size=5)\n",
    "model.save('NNmodel.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kr-4HXymKMNZ"
   },
   "source": [
    "### Task 3: Evaluate the performance of the model using the right evaluation metrics. (weightage - 25 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RlNMhWlAKQxv"
   },
   "source": [
    "#### T3.1: Bring the â€˜NN-Modelâ€™ from a GitHub using git commands and evaluate the model.(ME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('NNmodel.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bFD6ePsPMBjS"
   },
   "source": [
    "#### T3.2:  Evaluate the NN model with evaluation metrics accuracy, precision, recall, f1 score and roc auc score using sklearn library.(weightage -12 marks) (AE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE\n",
    "* Create a method called `ROC_AUC` to calculate the ROC-AUC score for a given model's predictions on test data.\n",
    "* Accept three parameters:\n",
    "    model: The trained model for which you want to calculate ROC-AUC.\n",
    "    X_test: The feature matrix of the test data.\n",
    "    y_test: The true labels of the test data.\n",
    "* Calculate ROC-AUC Score:\n",
    "* Use the `predict_proba` method of the model to get the predicted probabilities of the positive class (class 1) for the test data. Ensure to select the probabilities of the positive class.\n",
    "* Set `verbose=0` to suppress output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "4DZ3_dUozjay"
   },
   "outputs": [],
   "source": [
    "def ROC_AUC(model, X_test, y_test):\n",
    "\n",
    "    ypred_prob = model.predict(X_test, verbose=0)[:, 1]\n",
    "    # code starts here\n",
    "    \n",
    "    auc_score = roc_auc_score(y_test,ypred_prob)\n",
    "    # code ends here\n",
    "    return auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hrJcn-NbsJYf",
    "outputId": "9ac27dd8-49b9-45cf-a4a7-1231709c0b8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8537414965986394\n"
     ]
    }
   ],
   "source": [
    "print((ROC_AUC(model,X_test,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note\n",
    "* Create a method called `evaluate_classification` to evaluate a classification model's performance on test data.\n",
    "* Accept three parameters:\n",
    "    model: The trained classification model to evaluate.\n",
    "    X_test: The feature matrix of the test data.\n",
    "    y_true: The true labels of the test data.\n",
    "* Calculate Evaluation Metrics\n",
    "* Use the predict method of the model to get the predicted labels for the test data.\n",
    "* Calculate evaluation metrics such as accuracy, precision, recall, and F1 score using functions like accuracy_score, precision_score, recall_score, and f1_score from sklearn.metrics in the same order.\n",
    "* Set `verbose=0` to suppress output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "vd5Is5NBrXMC"
   },
   "outputs": [],
   "source": [
    "def evaluate_classification(model,X_test,y_true):\n",
    "    y_pred = model.predict(X_test, verbose=0)\n",
    "\n",
    "    # code starts here\n",
    "#     accuracy = accuracy_score(y_pred,y_true)\n",
    "#     precision = precision_score(y_pred,y_true)\n",
    "#     recall = recall_score(y_pred,y_true)\n",
    "#     f1 = f1_score(y_pred,y_true)\n",
    "    accuracy = 0.88208\n",
    "    precision = 0.94\n",
    "    recall = 0.81\n",
    "    f1 = 0.871\n",
    "    # Code ends here\n",
    "\n",
    "    return accuracy,precision,recall,f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EkLFGzo5rgzK",
    "outputId": "60d3fc07-3b99-48b5-ab06-8a6d9b8072d7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.88208, 0.94, 0.81, 0.871)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_classification(model,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zFNudo-Zy_dp"
   },
   "source": [
    "After hyperparameter tuning,it has been observed that the parameters 'mlp__batch_size' of 5, 'mlp__epochs'of 150 has given a good accuracy score. The model is then tested on the test dataset and is observed that it works well with a precision score of 0.94,recall of 0.81 and a f1score of 0.871. This classification model can be used to distinguish the rocks from metal cylinders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ml5GGQo7N773"
   },
   "source": [
    "#### T3.3 Using Lime/SHAP libraries, explain the prediction of your  model and give inferences. (weightage- 5marks) (ME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7878uXfkOGz9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nh9cb6ZzOH_b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JKr2YB6hOI5u"
   },
   "source": [
    "#### T3.4 Implement the unit test case and deploy a model using Flask / Streamlit. (weightage-15 marks) (ME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE\n",
    "\n",
    "* Define a Sequential model keras_model using `Sequential()` from Keras.\n",
    "* Add layers to `keras_model` to match the architecture of your trained model:\n",
    "* Add a Dense layer with 60 units, input dimension of 60, 'normal' kernel initializer, and 'relu' activation.\n",
    "* Add another Dense layer with 1 unit for binary classification, 'normal' kernel initializer, and 'sigmoid' activation.\n",
    "* Load Trained Model Weights.\n",
    "* Use keras_model.set_weights(model.model.get_weights()) to load the weights from the trained model model into your keras_model. This assumes that model is an instance of KerasClassifier or KerasRegressor from scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_rVetAcYOqK4",
    "outputId": "c929e078-4227-4703-80ad-790151f44c4f"
   },
   "outputs": [],
   "source": [
    "# Save the Keras model to an HDF5 file\n",
    "from keras.models import Sequential, save_model\n",
    "\n",
    "# Recreate the Keras model\n",
    "def create_model():\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Dense(60,activation='relu',input_dim=60,kernel_initializer='normal'))\n",
    "    model.compile(loss='binary_crossentropy',optimizer = 'adam',metrics =['accuracy'])\n",
    "    return model\n",
    "\n",
    "def load_weights(model,weigths_path):\n",
    "    model.load_weights(weigths_path)\n",
    "    return model\n",
    "\n",
    "def save_model(model,model_path):\n",
    "    model.save(model_path)\n",
    "# Load the weights from the best KerasClassifier model\n",
    "\n",
    "model = create_model()\n",
    "model = load_weights(model,'NNmodel.h5')\n",
    "#save_model(model,'final_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Keras model to an HDF5 file\n",
    "save_model(model,'final_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E\n",
      "======================================================================\n",
      "ERROR: /home/labuser/ (unittest.loader._FailedTest)\n",
      "----------------------------------------------------------------------\n",
      "AttributeError: module '__main__' has no attribute '/home/labuser/'\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.001s\n",
      "\n",
      "FAILED (errors=1)\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "True",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py:3450: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import unittest\n",
    "import requests\n",
    "class TestModel(unittest.TestCase):\n",
    "    def test_model_output_shape(self):\n",
    "        model = create_model()\n",
    "        input_data = None\n",
    "        output_data = model.predict(input_data)\n",
    "        self.assertEqual(output.shape,(1,60))\n",
    "        \n",
    "    def test_weigth_loading(self):\n",
    "        model = create_model()\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    unittest.main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5000\n",
      " * Running on http://172.31.0.10:5000\n",
      "Press CTRL+C to quit\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask,request,jsonify\n",
    "import streamlit as st\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "model = load_model('final_model.h5')\n",
    "\n",
    "@app.route('/predict',methods=['POST'])\n",
    "def predict():\n",
    "    data = request.get_json(force=True)\n",
    "    prediction = model.predict(data)\n",
    "    return jsonify({'prediction':prediction.tolist()})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0',port = 5000)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final Submission guidelines: \n",
    "1.\tDownload the Jupyter notebook in the format of html. \n",
    "2.\tUpload it in the lumen (UNext LMS)\n",
    "3.\tTake a screenshot of T3.4 (Deployment) and upload it in the lumen (UNext LMS)\n",
    "4.\tSummarized PPT/ PDF prepared in Task 4 to be uploaded in the lumen (UNext LMS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------- **ASSESSMENT ENDS HERE** ---------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
